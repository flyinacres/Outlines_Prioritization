{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Guided Generation Test\nOriginal code is from here: https://github.com/dottxt-ai/outlines\n\nThere were some questionable things in this code, so I worked with Google Gemini\nto clean and explain the code a little better.\n\nAccording to Gemini the code was also out-of-date...","metadata":{}},{"cell_type":"markdown","source":"# %%capture suppresses the long output \n\nAlso, fun fact, things like %%capture must be the very first line in a cell... ","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install outlines","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T02:53:17.670410Z","iopub.execute_input":"2026-01-09T02:53:17.671091Z","iopub.status.idle":"2026-01-09T02:53:22.785665Z","shell.execute_reply.started":"2026-01-09T02:53:17.671058Z","shell.execute_reply":"2026-01-09T02:53:22.784429Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%capture\n!pip install --upgrade transformers accelerate torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T02:53:30.357920Z","iopub.execute_input":"2026-01-09T02:53:30.358253Z","iopub.status.idle":"2026-01-09T02:57:13.612655Z","shell.execute_reply.started":"2026-01-09T02:53:30.358220Z","shell.execute_reply":"2026-01-09T02:57:13.611565Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T02:58:59.380924Z","iopub.execute_input":"2026-01-09T02:58:59.381598Z","iopub.status.idle":"2026-01-09T02:59:05.652082Z","shell.execute_reply.started":"2026-01-09T02:58:59.381565Z","shell.execute_reply":"2026-01-09T02:59:05.651442Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\nRequirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.49.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#imports\nimport outlines\nimport torch\nfrom enum import Enum\nfrom pydantic import BaseModel\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom typing import List\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T02:59:27.303374Z","iopub.execute_input":"2026-01-09T02:59:27.303698Z","iopub.status.idle":"2026-01-09T02:59:36.158085Z","shell.execute_reply.started":"2026-01-09T02:59:27.303671Z","shell.execute_reply":"2026-01-09T02:59:36.157521Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ---------------------------------------------------------\n# 1. SETUP: DEFINING THE \"SHAPE\" OF THE DATA\n# ---------------------------------------------------------\n# We aren't just writing a Python class here. Outlines will look at this \n# Pydantic model and convert it into a complex \"Grammar\" or Regex \n# behind the scenes. This acts like a stencil for the AI.\nclass TicketPriority(str, Enum):\n    low = \"low\"\n    medium = \"medium\"\n    high = \"high\"\n    urgent = \"urgent\"\n\nclass ServiceTicket(BaseModel):\n    priority: TicketPriority\n    category: str\n    requires_manager: bool\n    summary: str\n    action_items: List[str]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-09T03:00:03.699291Z","iopub.execute_input":"2026-01-09T03:00:03.700149Z","iopub.status.idle":"2026-01-09T03:00:03.800699Z","shell.execute_reply.started":"2026-01-09T03:00:03.700116Z","shell.execute_reply":"2026-01-09T03:00:03.800083Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"I was crashing Kaggle with this popup: Kernel Restarting\nThe kernel for notebook_source.ipynb appears to have died. It will restart automatically.\n\nSo we switched to a 4 bit quantitized model that is smaller, to try this again...","metadata":{}},{"cell_type":"code","source":"# ---------------------------------------------------------\n# 2. SETUP: LOADING THE BRAINS\n# ---------------------------------------------------------\nMODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\"\n\nprint(f\"\\nLoading {MODEL_NAME}...\")\n\n# This config loads the model in 4-bit mode. \n# It creates a tiny memory footprint so the kernel won't crash.\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)\n\nllm = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    device_map=\"cuda\",\n    quantization_config=quantization_config,\n    \n    # CRITICAL FIX 1: Use native code (Avoids DynamicCache error)\n    trust_remote_code=False, \n    \n    # CRITICAL FIX 2: Force standard attention (Prevents T4 Crash)\n    attn_implementation=\"eager\" \n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\n# Create the Outlines wrapper\n# outlines.from_transformers wraps the standard LLM. \n# It intercepts the model's generation process. When the model tries to \n# pick the next word, Outlines checks the Pydantic schema (ServiceTicket)\n# and bans any token that doesn't fit the JSON structure.\nwrapped_model = outlines.from_transformers(llm, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T03:00:07.221656Z","iopub.execute_input":"2026-01-09T03:00:07.222245Z","execution_failed":"2026-01-09T03:00:09.246Z"}},"outputs":[{"name":"stdout","text":"\nLoading microsoft/Phi-3-mini-4k-instruct...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed6121a6eba948279592345ca5124714"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# ---------------------------------------------------------\n# 3. THE INPUT\n# ---------------------------------------------------------\ncustomer_email = \"\"\"\nSubject: URGENT - Cannot access my account after payment\nI paid for the premium plan 3 hours ago and still can't access any features.\nPlease fix this immediately or refund my payment.\n\"\"\"\n\n# We format the prompt using Phi-3's specific chat template tags\n# (<|im_start|>, etc).\nprompt = f\"\"\"<|im_start|>user\nAnalyze this customer email:\n{customer_email}\n<|im_end|>\n<|im_start|>assistant\n\"\"\"\n\n# ---------------------------------------------------------\n# 4. EXECUTION: GENERATING THE TICKET\n# ---------------------------------------------------------\n# Here is the fix for the confusing variable usage.\n# When we pass `ServiceTicket` as the second argument, Outlines does three things:\n# 1. Forces the LLM to output valid JSON matching the ServiceTicket schema.\n# 2. Waits for generation to finish.\n# 3. AUTOMATICALLY converts that JSON string into a Python 'ServiceTicket' object.\nstructured_ticket_object = model(\n    prompt,\n    ServiceTicket,\n    max_new_tokens=500\n)\n\n# ---------------------------------------------------------\n# 5. LOGIC: USING THE RESULT\n# ---------------------------------------------------------\n# Because 'structured_ticket_object' is already a Python object, \n# we can access properties using dot notation (.priority) immediately.\n# No JSON parsing is required here.\n\ndef alert_manager(ticket):\n    print(f\"ALARM: {ticket.priority.upper()} priority issue: {ticket.summary}\")\n\n# We check the Enums and Booleans directly\nif structured_ticket_object.priority == TicketPriority.urgent or structured_ticket_object.requires_manager:\n    alert_manager(structured_ticket_object)\nelse:\n    print(\"Ticket routed to standard queue.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}